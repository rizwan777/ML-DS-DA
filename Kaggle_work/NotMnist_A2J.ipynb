{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydata = \".\\\\notMNIST_small\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "root_folders=list()\n",
    "for i in os.listdir(mydata):\n",
    "    root_folders.append(os.path.join(mydata,i))\n",
    "root_folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_img_Labels_file=list()\n",
    "for i,v in enumerate(root_folders):\n",
    "    print(i,v)\n",
    "    if v :\n",
    "        for file in os.listdir(v):\n",
    "            try:\n",
    "                file_path = os.path.join(v,file)\n",
    "                print(file_path)\n",
    "                img = cv2.imread(file_path,cv2.IMREAD_GRAYSCALE)\n",
    "                resize_img = cv2.resize(img,(100,100))\n",
    "                _img_Labels_file.append([i,resize_img])\n",
    "            except Exception as e:\n",
    "                pass\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is process to convert img to array \n",
    "# then we make it 1-D from 3-D\n",
    "# then we resize according to our needs here 100 X 100.\n",
    "img = \".\\\\notMNIST_small\\\\A\\\\MDEtMDEtMDAudHRm.png\"\n",
    "img = cv2.imread(img,cv2.IMREAD_GRAYSCALE)\n",
    "resize_img = cv2.resize(img,(100,100))\n",
    "height, width = resize_img.shape\n",
    "print(height, width, resize_img.shape, type(resize_img) )\n",
    "plt.imshow(img, cmap=\"binary\")\n",
    "plt.show()\n",
    "# cv2.imshow(\"A\",resize_img)\n",
    "\n",
    "# The OpenCV waitKey() function is a required keyboard binding \n",
    "# function after imwshow()\n",
    "# cv2.waitKey(0)\n",
    "\n",
    "# destroy all windows command\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets suffle data for randomly train to network.\n",
    "import random\n",
    "random.shuffle(_img_Labels_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets just check data is suffle or not\n",
    "for i in _img_Labels_file[10:20]:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X =[]\n",
    "Y =[]\n",
    "for labels, features  in enumerate(_img_Labels_file):\n",
    "#     print(labels , features)\n",
    "    X.append(features[1])\n",
    "    Y.append(features[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Features \",X[160],\"label \",Y[160]) \n",
    "# just we clarify weather our images will match with label or not.\n",
    "\n",
    "plt.imshow(X[160],cmap=\"binary\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# before we start doing our actual work firt we save our data\n",
    "import pickle\n",
    "pickle_out = open(\".\\\\NotMnist_filterd_data\\\\X_features.pickle\",\"wb\")\n",
    "pickle.dump(X, pickle_out)\n",
    "pickle_out.close()\n",
    "\n",
    "pickle_out = open(\".\\\\NotMnist_filterd_data\\\\Y_labels.pickle\",\"wb\")\n",
    "pickle.dump(Y, pickle_out)\n",
    "pickle_out.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets load again ... i'm just doing for good practice + save time while i need to play with it so no need to do again.\n",
    "import pickle\n",
    "X_features = pickle.load(open(\".\\\\NotMnist_filterd_data\\\\X_features.pickle\",\"rb\"))\n",
    "Y_labels = pickle.load(open(\".\\\\NotMnist_filterd_data\\\\Y_labels.pickle\",\"rb\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_features = np.array(X_features).reshape(-1,100,100,1) \n",
    "# we need to pass again three args overhear also otherwise its just make it single vector array.\n",
    "# Y_labels = np.array(Y_labels).reshape(-1,)\n",
    "X_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.5)\n",
    "sess = tf.Session(config = tf.ConfigProto(gpu_options=gpu_options))\n",
    "# normalization of data for easy to calculations.\n",
    "X_features = X_features/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i dont want to run and test now its take time to train the data.\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Conv2D,Activation,MaxPool2D,Dropout,Flatten\n",
    "model = Sequential()\n",
    "model.add(Conv2D(256,(3,3),input_shape=X_features.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Conv2D(256,(3,3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss=\"binary_crossentropy\",optimizer=\"adam\",metrics=['accuracy'])\n",
    "model.fit(X_features,Y,batch_size=64,epochs=3,validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
